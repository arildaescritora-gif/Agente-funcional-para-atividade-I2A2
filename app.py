# -*- coding: utf-8 -*-

import streamlit as st
import numpy as np
import zipfile
import io
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import re 
import plotly.express as px 
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from tabulate import tabulate 

# --- Configura√ß√£o da Chave de API do Google ---
try:
    google_api_key = st.secrets["google_ai"]["google_api_key"]
except KeyError:
    st.error("Chave de API do Google n√£o encontrada. Certifique-se de adicion√°-la nos 'Secrets' da sua aplica√ß√£o.")
    st.stop()

# --- Defini√ß√£o das Ferramentas (Tools) ---

def show_descriptive_stats(*args):
    """
    Gera estat√≠sticas descritivas para todas as colunas de um DataFrame.
    Retorna um dicion√°rio com o resumo estat√≠stico.
    """
    df = st.session_state.df
    stats = df.describe(include='all').to_markdown(tablefmt="pipe")
    return {"status": "success", "data": stats, "message": "Estat√≠sticas descritivas geradas."}


def generate_histogram(column: str, *args):
    """
    Gera um histograma interativo Plotly para uma coluna num√©rica espec√≠fica do DataFrame.
    A entrada deve ser o nome da coluna (ex: 'amount', 'v5', 'time').
    """
    df = st.session_state.df
    column = column.lower()
    
    if column not in df.columns:
        return {"status": "error", "message": f"Erro: A coluna '{column}' n√£o foi encontrada no DataFrame. Por favor, verifique se o nome est√° correto."}
    if not pd.api.types.is_numeric_dtype(df[column]):
        return {"status": "error", "message": f"Erro: A coluna '{column}' n√£o √© num√©rica. Forne√ßa uma coluna num√©rica para gerar um histograma."}
    
    # Usando Plotly Express
    fig = px.histogram(df, x=column, title=f'Distribui√ß√£o de {column}')
    return {"status": "success", "plotly_figure": fig, "message": f"O histograma da coluna '{column}' foi gerado com sucesso. Analise a distribui√ß√£o dos dados e procure por assimetrias ou picos."}


def generate_correlation_heatmap(*args):
    """
    Calcula a matriz de correla√ß√£o entre as vari√°veis num√©ricas do DataFrame
    e gera um mapa de calor (heatmap) interativo Plotly.
    """
    df = st.session_state.df
    numeric_cols = df.select_dtypes(include=np.number).columns
    if len(numeric_cols) < 2:
        return {"status": "error", "message": "Erro: O DataFrame n√£o tem colunas num√©ricas suficientes para calcular a correla√ß√£o."}
    
    correlation_matrix = df[numeric_cols].corr()
    
    # Usando Plotly Express
    fig = px.imshow(
        correlation_matrix,
        text_auto=".2f",
        aspect="auto",
        title='Mapa de Calor da Matriz de Correla√ß√£o',
        color_continuous_scale='RdBu_r'
    )
    fig.update_xaxes(side="top")
    return {"status": "success", "plotly_figure": fig, "message": "O mapa de calor da correla√ß√£o interativo foi gerado. Analise o padr√£o de cores para identificar rela√ß√µes fortes (vermelho/azul escuro) ou fracas (cinza claro)."}


def generate_scatter_plot(columns_str: str, *args):
    """
    Gera um gr√°fico de dispers√£o (scatter plot) interativo Plotly para visualizar 
    a rela√ß√£o entre duas colunas num√©ricas.
    A entrada DEVE ser uma string contendo os nomes das duas colunas SEPARADAS por um espa√ßo, 
    v√≠rgula ou 'e' (ex: 'time, amount' ou 'v1 e v2').
    """
    df = st.session_state.df
    
    col_names = re.split(r'[,\s]+', columns_str.lower())
    col_names = [col for col in col_names if col and col != 'e'] 
    
    if len(col_names) < 2:
         return {"status": "error", "message": f"Erro de Argumentos: O agente precisa de pelo menos DOIS nomes de coluna para o gr√°fico de dispers√£o. Foi encontrado apenas: {col_names}"}

    x_col = col_names[0]
    y_col = col_names[1]

    if x_col not in df.columns or y_col not in df.columns:
        return {"status": "error", "message": f"Erro: Uma ou ambas as colunas ('{x_col}', '{y_col}') n√£o existem no DataFrame."}
    
    # Usando Plotly Express
    fig = px.scatter(df, x=x_col, y=y_col, title=f'Gr√°fico de Dispers√£o: {x_col} vs {y_col}')
    return {"status": "success", "plotly_figure": fig, "message": f"O gr√°fico de dispers√£o interativo para '{x_col}' vs '{y_col}' foi gerado. Use-o para visualizar a forma e a densidade da rela√ß√£o entre essas vari√°veis."}


def detect_outliers_isolation_forest(*args):
    """
    Detecta anomalias (outliers) no DataFrame usando o algoritmo Isolation Forest.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    Retorna o n√∫mero de anomalias detectadas e uma amostra dos outliers.
    """
    try:
        df = st.session_state.df
        feature_cols = [col for col in df.columns if col.startswith('v')] + ['time', 'amount']
        
        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
             return {"status": "error", "message": "Erro ao detectar anomalias: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame."}

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)
        model = IsolationForest(contamination=0.01, random_state=42)
        df['anomaly_score'] = model.fit_predict(df_scaled)
        outliers = df[df['anomaly_score'] == -1]
        
        message = f"O algoritmo Isolation Forest detectou {len(outliers)} transa√ß√µes at√≠picas (outliers)."
        if not outliers.empty:
            message += "\nAmostra das transa√ß√µes detectadas como anomalias:\n" + outliers.head().to_markdown(tablefmt="pipe")
            
        return {"status": "success", "message": message}
    except Exception as e:
        return {"status": "error", "message": f"Erro ao detectar anomalias: {e}"}


def find_clusters_kmeans(n_clusters: str, *args):
    """
    Realiza agrupamento (clustering) nos dados usando o algoritmo K-Means.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    A entrada DEVE ser o n√∫mero de clusters desejado (como string, ex: "5").
    Retorna uma descri√ß√£o dos clusters encontrados.
    """
    try:
        n_clusters = int(n_clusters)
    except ValueError:
         return {"status": "error", "message": f"O n√∫mero de clusters deve ser um n√∫mero inteiro, mas o valor recebido foi '{n_clusters}'."}

    try:
        df = st.session_state.df
        feature_cols = [col for col in df.columns if col.startswith('v')] + ['time', 'amount']
        
        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
             return {"status": "error", "message": "Erro ao encontrar clusters: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame."}

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
        df['cluster'] = kmeans.fit_predict(df_scaled)
        
        cluster_summary = df.groupby('cluster').agg({
            'amount': ['mean', 'min', 'max'],
            'time': ['min', 'max']
        }).to_markdown(tablefmt="pipe")
        
        message = f"O agrupamento K-Means com {n_clusters} clusters foi conclu√≠do."
        message += "\nCaracter√≠sticas dos Clusters:\n" + cluster_summary
        
        return {"status": "success", "message": message}
    except Exception as e:
        return {"status": "error", "message": f"Erro ao realizar o agrupamento com K-Means: {e}"}


# --- Fun√ß√µes de Carregamento e Interface ---

@st.cache_data(show_spinner=False)
def load_and_extract_data(uploaded_file):
    if uploaded_file is None:
        return {"status": "error", "message": "Nenhum arquivo enviado."}

    try:
        if uploaded_file.name.endswith('.zip'):
            with zipfile.ZipFile(uploaded_file, 'r') as z:
                with z.open(z.namelist()[0]) as f:
                    df = pd.read_csv(f)
        elif uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            return {"status": "error", "message": "Formato de arquivo n√£o suportado. Por favor, envie um arquivo ZIP ou CSV."}

        df.columns = [col.lower() for col in df.columns]

        return {"status": "success", "df": df, "message": f"Arquivo '{uploaded_file.name}' carregado com sucesso. DataFrame pronto para an√°lise."}

    except Exception as e:
        return {"status": "error", "message": f"Erro ao processar o arquivo: {e}"}


def initialize_agent(tools_list, system_prompt_text):
    llm = ChatGoogleGenAI(
        # V13: APENAS o modelo gemma2-9b-it
        model="gemma2-9b-it",
        google_api_key=google_api_key,
        temperature=0.0
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_text),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    memory = ConversationBufferWindowMemory(k=5, memory_key="chat_history", return_messages=True)

    agent = create_tool_calling_agent(llm, tools_list, prompt)

    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools_list,
        verbose=True,
        memory=memory,
        max_iterations=15
    )
    return agent_executor


# --- Interface do Streamlit ---

st.set_page_config(page_title="Agente de An√°lise de Dados (Gemma)", layout="wide")

st.title("ü§ñ Agente de An√°lise de Dados (EDA) com Gemma")
st.markdown("Envie um arquivo CSV (ou ZIP com CSV) e pergunte ao agente para realizar an√°lises, como correla√ß√£o, estat√≠sticas descritivas ou detec√ß√£o de anomalias.")

# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None
if "agent_executor" not in st.session_state:
    st.session_state.agent_executor = None

# Sidebar para upload de arquivo
with st.sidebar:
    st.header("Upload do Arquivo de Dados")
    uploaded_file = st.file_uploader("Escolha um arquivo CSV ou ZIP", type=["csv", "zip"])

    if st.button("Carregar Dados e Inicializar Agente") and uploaded_file is not None:
        with st.spinner("Carregando e preparando dados..."):
            load_result = load_and_extract_data(uploaded_file)

        if load_result["status"] == "success":
            st.session_state.df = load_result["df"]

            tools_with_df = [
                Tool(name=show_descriptive_stats.__name__, description=show_descriptive_stats.__doc__, func=show_descriptive_stats),
                Tool(name=generate_histogram.__name__, description=generate_histogram.__doc__, func=generate_histogram),
                Tool(name=generate_correlation_heatmap.__name__, description=generate_correlation_heatmap.__doc__, func=generate_correlation_heatmap),
                Tool(name=generate_scatter_plot.__name__, description=generate_scatter_plot.__doc__, func=generate_scatter_plot),
                Tool(name=detect_outliers_isolation_forest.__name__, description=detect_outliers_isolation_forest.__doc__, func=detect_outliers_isolation_forest),
                Tool(name=find_clusters_kmeans.__name__, description=find_clusters_kmeans.__doc__, func=find_clusters_kmeans)
            ]

            # O prompt permanece o agressivo da V11
            system_prompt = (
                "Voc√™ √© um agente de An√°lise Explorat√≥ria de Dados (EDA) altamente proficiente. "
                "Sua **PRIMEIRA PRIORIDADE** √© sempre tentar responder √† pergunta do usu√°rio usando uma das ferramentas dispon√≠veis, "
                "especialmente as ferramentas de visualiza√ß√£o ('generate_correlation_heatmap', 'generate_scatter_plot', 'generate_histogram'). "
                "**SEMPRE** que o usu√°rio solicitar uma an√°lise de dados (ex: 'correla√ß√£o', 'distribui√ß√£o', 'rela√ß√£o', 'gr√°fico'), "
                "voc√™ **DEVE** selecionar a ferramenta apropriada e execut√°-la, a menos que os argumentos necess√°rios n√£o sejam fornecidos. "
                "N√£o pe√ßa confirma√ß√£o antes de gerar um gr√°fico se o usu√°rio j√° o solicitou. "
                "Quando uma ferramenta retorna 'plotly_figure', o gr√°fico ser√° exibido; voc√™ deve ent√£o descrever o que ele mostra. "
                "N√£o hesite. A√ß√£o acima de tudo."
                "Lembre-se: todas as colunas V* e 'Time' e 'Amount' foram convertidas para min√∫sculas ('v*', 'time', 'amount') no DataFrame. "
                "Sua resposta final deve sempre ser em Portugu√™s e oferecer insights."
            )

            st.session_state.agent_executor = initialize_agent(tools_with_df, system_prompt)
            st.success("Dados carregados e agente inicializado! Voc√™ pode come√ßar a perguntar.")

        else:
            st.error(load_result["message"])

    if st.session_state.df is not None:
        st.success(f"DataFrame carregado com {len(st.session_state.df)} linhas e {len(st.session_state.df.columns)} colunas.")
        st.subheader("Visualiza√ß√£o dos Dados (Amostra)")
        st.dataframe(st.session_state.df.head())


# Exibir hist√≥rico de mensagens (Apenas texto e tabelas s√£o mantidos na mem√≥ria)
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if isinstance(message["content"], pd.DataFrame):
             st.dataframe(message["content"])
        elif isinstance(message["content"], str):
             st.markdown(message["content"])

# Tratamento de entrada do usu√°rio
if prompt_input := st.chat_input("Qual an√°lise voc√™ gostaria de fazer? (Ex: 'Gere um mapa de calor da correla√ß√£o')"):
    
    with st.chat_message("user"):
        st.markdown(prompt_input)
    st.session_state.messages.append({"role": "user", "content": prompt_input})
    
    if st.session_state.agent_executor is not None:
        with st.chat_message("assistant"):
            st_callback = st.container()
            
            try:
                full_response = st.session_state.agent_executor.invoke({"input": prompt_input})
                response_content = full_response["output"]

                if isinstance(response_content, dict) and response_content.get("status") in ["success", "error"]:
                    
                    # RENDERIZA√á√ÉO V10: Usa st.write() - A fun√ß√£o mais tolerante para objetos Plotly
                    if "plotly_figure" in response_content:
                        # Exibe o gr√°fico Plotly. st.write √© mais robusto contra falhas de renderiza√ß√£o.
                        st_callback.write(response_content["plotly_figure"])
                    
                    # Exibir e salvar a MENSAGEM de texto
                    if "message" in response_content:
                        st_callback.markdown(response_content["message"])
                        st.session_state.messages.append({"role": "assistant", "content": response_content["message"]})
                    
                    if "data" in response_content:
                        df_display = pd.read_markdown(response_content["data"])
                        st_callback.dataframe(df_display)
                        st.session_state.messages.append({"role": "assistant", "content": df_display})
                    
                    if response_content.get("status") == "error":
                         st_callback.error(response_content["message"])
                    
                else:
                    st_callback.markdown(str(response_content))
                    st.session_state.messages.append({"role": "assistant", "content": str(response_content)})

            except Exception as e:
                # Alterado para uma mensagem de erro mais gen√©rica, pois o erro max_retries √© interno.
                error_message = f"Desculpe, ocorreu um erro inesperado na an√°lise: {e}. Isso pode ser um problema de compatibilidade interna do modelo ou limites de recurso."
                st_callback.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
