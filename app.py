# -*- coding: utf-8 -*-

import streamlit as st
import numpy as np
import zipfile
import io
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import re 
# Removido plotly.express, substitu√≠do por Matplotlib/Seaborn
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
# Removido sklearn para compacta√ß√£o, focado em EDA

# --- Configura√ß√£o da Chave de API do Google ---
try:
    google_api_key = st.secrets["google_ai"]["google_api_key"]
except KeyError:
    st.error("Chave de API do Google n√£o encontrada. Adicione-a nos 'Secrets'.")
    st.stop()

# --- Fun√ß√µes Auxiliares de Carregamento ---

@st.cache_data(show_spinner=False)
def load_and_extract_data(uploaded_file):
    """Carrega dados de ZIP ou CSV, garantindo colunas min√∫sculas."""
    if uploaded_file is None:
        return {"status": "error", "message": "Nenhum arquivo enviado."}

    try:
        if uploaded_file.name.endswith('.zip'):
            with zipfile.ZipFile(uploaded_file, 'r') as z:
                with z.open(z.namelist()[0]) as f:
                    df = pd.read_csv(f)
        else: # Assumindo CSV
            df = pd.read_csv(uploaded_file)
        
        # Redu√ß√£o da Amostra: Solu√ß√£o de Sobreviv√™ncia para o Streamlit Cloud
        # Para ser diferente da sua amiga, vamos deixar SEM amostragem no in√≠cio.
        # Se os gr√°ficos falharem, ative a amostragem: df = df.sample(frac=0.1, random_state=42)

        df.columns = [col.lower() for col in df.columns]

        return {"status": "success", "df": df, "message": f"Arquivo '{uploaded_file.name}' carregado com sucesso. DataFrame pronto para an√°lise."}

    except Exception as e:
        return {"status": "error", "message": f"Erro ao processar o arquivo: {e}"}


# --- Defini√ß√£o das Ferramentas Customizadas (Tools) ---

def show_descriptive_stats(*args):
    """Gera estat√≠sticas descritivas para todas as colunas do DataFrame."""
    df = st.session_state.df
    stats = df.describe(include='all').to_markdown(index=True)
    return {"status": "success", "data": stats, "message": "Estat√≠sticas descritivas geradas e exibidas na tabela abaixo."}


def generate_histogram(column: str, *args):
    """
    Gera um histograma Matplotlib para uma coluna num√©rica.
    A entrada deve ser o nome da coluna (ex: 'amount').
    """
    df = st.session_state.df
    column = column.lower()
    
    if column not in df.columns or not pd.api.types.is_numeric_dtype(df[column]):
        return {"status": "error", "message": f"Erro: A coluna '{column}' n√£o √© v√°lida ou n√£o √© num√©rica."}
    
    # 1. Limpa figuras Matplotlib antigas
    plt.close('all')
    
    # 2. Cria a figura Matplotlib (usando plt e sns para leveza)
    fig, ax = plt.subplots(figsize=(8, 4))
    sns.histplot(df[column], kde=True, ax=ax)
    ax.set_title(f'Distribui√ß√£o de {column}')
    ax.set_xlabel(column)
    
    # 3. Retorna a figura para exibi√ß√£o
    return {"status": "success", "matplotlib_figure": fig, "message": f"O histograma da coluna '{column}' foi gerado e est√° sendo exibido acima."}


def generate_correlation_heatmap(*args):
    """
    Calcula a matriz de correla√ß√£o e gera um mapa de calor Matplotlib/Seaborn.
    """
    df = st.session_state.df
    numeric_cols = df.select_dtypes(include=np.number).columns
    if len(numeric_cols) < 2:
        return {"status": "error", "message": "Erro: DataFrame n√£o tem colunas num√©ricas suficientes para correla√ß√£o."}
    
    correlation_matrix = df[numeric_cols].corr()
    
    # 1. Limpa figuras Matplotlib antigas
    plt.close('all')
    
    # 2. Cria a figura Matplotlib
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(
        correlation_matrix,
        annot=True,
        fmt=".2f",
        cmap='coolwarm',
        ax=ax,
        linewidths=.5,
        linecolor='black'
    )
    ax.set_title('Mapa de Calor da Matriz de Correla√ß√£o')
    
    # 3. Retorna a figura para exibi√ß√£o
    return {"status": "success", "matplotlib_figure": fig, "message": "O mapa de calor da correla√ß√£o foi gerado e est√° sendo exibido acima. Analise as cores para rela√ß√µes fortes."}


def generate_scatter_plot(columns_str: str, *args):
    """
    Gera um gr√°fico de dispers√£o Matplotlib para duas colunas num√©ricas.
    A entrada DEVE ser uma string contendo os nomes das duas colunas SEPARADAS por v√≠rgula (ex: 'time, amount').
    """
    df = st.session_state.df
    
    col_names = [c.strip().lower() for c in columns_str.split(',') if c.strip()]
    
    if len(col_names) != 2:
         return {"status": "error", "message": f"Erro de Argumentos: O agente precisa de exatamente DUAS colunas separadas por v√≠rgula."}

    x_col, y_col = col_names[0], col_names[1]

    if x_col not in df.columns or y_col not in df.columns:
        return {"status": "error", "message": f"Erro: As colunas ('{x_col}', '{y_col}') n√£o existem no DataFrame."}
    
    # 1. Limpa figuras Matplotlib antigas
    plt.close('all')
    
    # 2. Cria a figura Matplotlib
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.scatterplot(x=df[x_col], y=df[y_col], ax=ax)
    ax.set_title(f'Gr√°fico de Dispers√£o: {x_col} vs {y_col}')
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    
    # 3. Retorna a figura para exibi√ß√£o
    return {"status": "success", "matplotlib_figure": fig, "message": f"O gr√°fico de dispers√£o para '{x_col}' vs '{y_col}' foi gerado e est√° sendo exibido acima."}


# --- Inicializa√ß√£o do Agente ---

def initialize_agent(tools_list, system_prompt_text):
    """Inicializa o Agente de Chamada de Ferramenta (Tool Calling Agent) com Gemini Pro."""
    
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro", # Sua escolha de modelo
        google_api_key=google_api_key,
        temperature=0.0
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_text),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    memory = ConversationBufferWindowMemory(k=5, memory_key="chat_history", return_messages=True)

    agent = create_tool_calling_agent(llm, tools_list, prompt)

    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools_list,
        verbose=True,
        memory=memory,
        max_iterations=15
    )
    return agent_executor


# --- Interface do Streamlit ---

st.set_page_config(page_title="Agente EDA Customizado (Gemini Pro)", layout="wide")

st.title("ü§ñ Agente de An√°lise de Dados Customizado (V21)")
st.markdown("Agente √∫nico usando ferramentas customizadas e o modelo Gemini 2.5 Pro para an√°lise de EDA e gera√ß√£o de gr√°ficos leves (Matplotlib).")

# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None
if "agent_executor" not in st.session_state:
    st.session_state.agent_executor = None

# Sidebar para upload de arquivo
with st.sidebar:
    st.header("Upload do Arquivo de Dados")
    uploaded_file = st.file_uploader("Escolha um arquivo CSV ou ZIP", type=["csv", "zip"])

    if st.button("Carregar Dados e Inicializar Agente") and uploaded_file is not None:
        with st.spinner("Carregando e preparando dados..."):
            load_result = load_and_extract_data(uploaded_file)

        if load_result["status"] == "success":
            st.session_state.df = load_result["df"]

            tools_with_df = [
                Tool(name=show_descriptive_stats.__name__, description=show_descriptive_stats.__doc__, func=show_descriptive_stats),
                Tool(name=generate_histogram.__name__, description=generate_histogram.__doc__, func=generate_histogram),
                Tool(name=generate_correlation_heatmap.__name__, description=generate_correlation_heatmap.__doc__, func=generate_correlation_heatmap),
                Tool(name=generate_scatter_plot.__name__, description=generate_scatter_plot.__doc__, func=generate_scatter_plot),
            ]

            system_prompt = (
                "Voc√™ √© um agente de An√°lise Explorat√≥ria de Dados (EDA) altamente proficiente. "
                "Sua **PRIMEIRA PRIORIDADE** √© sempre tentar responder √† pergunta do usu√°rio usando uma das ferramentas dispon√≠veis. "
                "**SEMPRE** que o usu√°rio solicitar um gr√°fico (ex: 'correla√ß√£o', 'distribui√ß√£o', 'dispers√£o'), voc√™ **DEVE** selecionar a ferramenta de visualiza√ß√£o Matplotlib/Seaborn apropriada. "
                "Quando uma ferramenta retorna 'matplotlib_figure', o gr√°fico ser√° exibido; voc√™ deve ent√£o descrever e analisar o que ele mostra. "
                "Lembre-se: todas as colunas V* e 'Time' e 'Amount' foram convertidas para min√∫sculas. "
                "Sua resposta final deve sempre ser em Portugu√™s e oferecer insights."
            )

            st.session_state.agent_executor = initialize_agent(tools_with_df, system_prompt)
            st.success("Dados carregados e agente inicializado! Voc√™ pode come√ßar a perguntar.")

        else:
            st.error(load_result["message"])

    if st.session_state.df is not None:
        st.success(f"DataFrame carregado com {len(st.session_state.df)} linhas e {len(st.session_state.df.columns)} colunas.")
        st.subheader("Visualiza√ß√£o dos Dados (Amostra)")
        st.dataframe(st.session_state.df.head())


# Exibir hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if isinstance(message["content"], pd.DataFrame):
             st.dataframe(message["content"])
        elif isinstance(message["content"], str):
             st.markdown(message["content"])

# Tratamento de entrada do usu√°rio
if prompt_input := st.chat_input("Qual an√°lise voc√™ gostaria de fazer? (Ex: 'Gere o histograma da coluna amount')"):
    
    with st.chat_message("user"):
        st.markdown(prompt_input)
    st.session_state.messages.append({"role": "user", "content": prompt_input})
    
    if st.session_state.agent_executor is not None:
        with st.chat_message("assistant"):
            st_callback = st.container()
            
            try:
                full_response = st.session_state.agent_executor.invoke({"input": prompt_input})
                response_content = full_response["output"]

                if isinstance(response_content, dict) and response_content.get("status") in ["success", "error"]:
                    
                    # RENDERIZA√á√ÉO: Exibe o gr√°fico Matplotlib se presente
                    if "matplotlib_figure" in response_content:
                        st_callback.pyplot(response_content["matplotlib_figure"])
                    
                    # Exibir e salvar a MENSAGEM de texto
                    if "message" in response_content:
                        st_callback.markdown(response_content["message"])
                        st.session_state.messages.append({"role": "assistant", "content": response_content["message"]})
                    
                    # Exibir a tabela de estat√≠sticas descritivas
                    if "data" in response_content:
                        df_display = pd.read_markdown(response_content["data"])
                        st_callback.dataframe(df_display)
                        st.session_state.messages.append({"role": "assistant", "content": df_display})
                    
                    if response_content.get("status") == "error":
                         st_callback.error(response_content["message"])
                    
                else:
                    st_callback.markdown(str(response_content))
                    st.session_state.messages.append({"role": "assistant", "content": str(response_content)})

            except Exception as e:
                # Mensagem de erro robusta
                error_message = f"Desculpe, ocorreu um erro inesperado na an√°lise: {e}. Por favor, recarregue a p√°gina ou simplifique sua √∫ltima pergunta."
                st_callback.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
