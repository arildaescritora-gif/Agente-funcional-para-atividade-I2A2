# -*- coding: utf-8 -*-

import streamlit as st
import numpy as np
import zipfile
import io
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferWindowMemory
from sklearn.ensemble import IsolationForest
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from tabulate import tabulate 

# --- Configura√ß√£o da Chave de API do Google ---
try:
    google_api_key = st.secrets["google_ai"]["google_api_key"]
except KeyError:
    st.error("Chave de API do Google n√£o encontrada. Certifique-se de adicion√°-la nos 'Secrets' da sua aplica√ß√£o.")
    st.stop()

# --- Defini√ß√£o das Ferramentas (Tools) ---
# O DataFrame (df) √© lido diretamente de st.session_state.df dentro da fun√ß√£o.

def show_descriptive_stats(*args):
    """
    Gera estat√≠sticas descritivas para todas as colunas de um DataFrame.
    Retorna um dicion√°rio com o resumo estat√≠stico.
    """
    df = st.session_state.df
    stats = df.describe(include='all').to_markdown(tablefmt="pipe")
    return {"status": "success", "data": stats, "message": "Estat√≠sticas descritivas geradas."}


def generate_histogram(column: str, *args):
    """
    Gera um histograma para uma coluna num√©rica espec√≠fica do DataFrame.
    A entrada deve ser o nome da coluna (ex: 'amount', 'v5', 'time').
    """
    df = st.session_state.df
    # For√ßando a coluna para min√∫sculas
    column = column.lower()
    
    if column not in df.columns:
        return {"status": "error", "message": f"Erro: A coluna '{column}' n√£o foi encontrada no DataFrame. Por favor, verifique se o nome est√° correto."}
    if not pd.api.types.is_numeric_dtype(df[column]):
        return {"status": "error", "message": f"Erro: A coluna '{column}' n√£o √© num√©rica. Forne√ßa uma coluna num√©rica para gerar um histograma."}
    
    fig, ax = plt.subplots()
    df[column].hist(ax=ax)
    ax.set_title(f'Distribui√ß√£o de {column}')
    ax.set_xlabel(column)
    ax.set_ylabel('Frequ√™ncia')
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return {"status": "success", "image": buf, "message": f"O histograma da coluna '{column}' foi gerado com sucesso."}


def generate_correlation_heatmap(*args):
    """
    Calcula a matriz de correla√ß√£o entre as vari√°veis num√©ricas do DataFrame
    e gera um mapa de calor (heatmap) para visualiza√ß√£o.
    """
    df = st.session_state.df
    numeric_cols = df.select_dtypes(include=np.number).columns
    if len(numeric_cols) < 2:
        return {"status": "error", "message": "Erro: O DataFrame n√£o tem colunas num√©ricas suficientes para calcular a correla√ß√£o."}
    
    correlation_matrix = df[numeric_cols].corr()
    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", ax=ax)
    ax.set_title('Mapa de Calor da Matriz de Correla√ß√£o')
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return {"status": "success", "image": buf, "message": "O mapa de calor da correla√ß√£o foi gerado com sucesso."}


def generate_scatter_plot(x_col: str, y_col: str, *args):
    """
    Gera um gr√°fico de dispers√£o (scatter plot) para visualizar a rela√ß√£o entre duas colunas num√©ricas.
    As entradas DEVE ser os nomes das colunas X e Y SEPARADAMENTE (ex: x_col='time', y_col='amount').
    """
    df = st.session_state.df
    
    # CORRIGIDO: O agente falhou porque a entrada foi amb√≠gua. A valida√ß√£o Pydantic precisa dos dois
    # argumentos. Vamos garantir que eles existam antes de prosseguir.
    if not x_col or not y_col:
         return {"status": "error", "message": "Erro de Argumentos: Para gerar o gr√°fico de dispers√£o, o agente precisa de DOIS nomes de coluna distintos para os eixos X e Y."}

    # For√ßando as colunas para min√∫sculas
    x_col = x_col.lower()
    y_col = y_col.lower()
    
    if x_col not in df.columns or y_col not in df.columns:
        return {"status": "error", "message": f"Erro: Uma ou ambas as colunas ('{x_col}', '{y_col}') n√£o existem no DataFrame."}
    
    fig, ax = plt.subplots()
    df.plot.scatter(x=x_col, y=y_col, ax=ax)
    ax.set_title(f'Gr√°fico de Dispers√£o: {x_col} vs {y_col}')
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    plt.close(fig)
    return {"status": "success", "image": buf, "message": f"O gr√°fico de dispers√£o para '{x_col}' vs '{y_col}' foi gerado com sucesso."}


def detect_outliers_isolation_forest(*args):
    """
    Detecta anomalias (outliers) no DataFrame usando o algoritmo Isolation Forest.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    Retorna o n√∫mero de anomalias detectadas e uma amostra dos outliers.
    """
    try:
        df = st.session_state.df
        # Nomes das colunas ajustados para min√∫sculas ('time', 'amount')
        feature_cols = [col for col in df.columns if col.startswith('v')] + ['time', 'amount']
        
        # Filtra apenas colunas que realmente existem no DF
        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
             return {"status": "error", "message": "Erro ao detectar anomalias: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame."}

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)
        model = IsolationForest(contamination=0.01, random_state=42)
        df['anomaly_score'] = model.fit_predict(df_scaled)
        outliers = df[df['anomaly_score'] == -1]
        
        message = f"O algoritmo Isolation Forest detectou {len(outliers)} transa√ß√µes at√≠picas (outliers)."
        if not outliers.empty:
            message += "\nAmostra das transa√ß√µes detectadas como anomalias:\n" + outliers.head().to_markdown(tablefmt="pipe")
            
        return {"status": "success", "message": message}
    except Exception as e:
        return {"status": "error", "message": f"Erro ao detectar anomalias: {e}"}


def find_clusters_kmeans(n_clusters: str, *args):
    """
    Realiza agrupamento (clustering) nos dados usando o algoritmo K-Means.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    A entrada DEVE ser o n√∫mero de clusters desejado (como string, ex: "5").
    Retorna uma descri√ß√£o dos clusters encontrados.
    """
    try:
        # Converte o input (que √© uma string por causa do bug de LLM) para int
        n_clusters = int(n_clusters)
    except ValueError:
         return {"status": "error", "message": f"O n√∫mero de clusters deve ser um n√∫mero inteiro, mas o valor recebido foi '{n_clusters}'."}

    try:
        df = st.session_state.df
        # Nomes das colunas ajustados para min√∫sculas ('time', 'amount')
        feature_cols = [col for col in df.columns if col.startswith('v')] + ['time', 'amount']
        
        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
             return {"status": "error", "message": "Erro ao encontrar clusters: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame."}

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)
        
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init='auto')
        df['cluster'] = kmeans.fit_predict(df_scaled)
        
        cluster_summary = df.groupby('cluster').agg({
            'amount': ['mean', 'min', 'max'],
            'time': ['min', 'max']
        }).to_markdown(tablefmt="pipe")
        
        message = f"O agrupamento K-Means com {n_clusters} clusters foi conclu√≠do."
        message += "\nCaracter√≠sticas dos Clusters:\n" + cluster_summary
        
        return {"status": "success", "message": message}
    except Exception as e:
        return {"status": "error", "message": f"Erro ao realizar o agrupamento com K-Means: {e}"}


# --- Fun√ß√µes de Carregamento e Interface ---

@st.cache_data(show_spinner=False)
def load_and_extract_data(uploaded_file):
    if uploaded_file is None:
        return {"status": "error", "message": "Nenhum arquivo enviado."}

    try:
        if uploaded_file.name.endswith('.zip'):
            with zipfile.ZipFile(uploaded_file, 'r') as z:
                with z.open(z.namelist()[0]) as f:
                    df = pd.read_csv(f)
        elif uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            return {"status": "error", "message": "Formato de arquivo n√£o suportado. Por favor, envie um arquivo ZIP ou CSV."}

        # CR√çTICO: Renomear colunas para min√∫sculas para padroniza√ß√£o.
        df.columns = [col.lower() for col in df.columns]

        return {"status": "success", "df": df, "message": f"Arquivo '{uploaded_file.name}' carregado com sucesso. DataFrame pronto para an√°lise."}

    except Exception as e:
        return {"status": "error", "message": f"Erro ao processar o arquivo: {e}"}


def initialize_agent(tools_list, system_prompt_text):
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        google_api_key=google_api_key,
        temperature=0.0
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_text),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    memory = ConversationBufferWindowMemory(k=5, memory_key="chat_history", return_messages=True)

    agent = create_tool_calling_agent(llm, tools_list, prompt)

    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools_list,
        verbose=True,
        memory=memory,
        max_iterations=15
    )
    return agent_executor


# --- Interface do Streamlit ---

st.set_page_config(page_title="Agente de An√°lise de Dados (Gemini/LangChain)", layout="wide")

st.title("ü§ñ Agente de An√°lise de Dados (EDA) com Gemini")
st.markdown("Envie um arquivo CSV (ou ZIP com CSV) e pergunte ao agente para realizar an√°lises, como correla√ß√£o, estat√≠sticas descritivas ou detec√ß√£o de anomalias.")

# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None
if "agent_executor" not in st.session_state:
    st.session_state.agent_executor = None

# Sidebar para upload de arquivo
with st.sidebar:
    st.header("Upload do Arquivo de Dados")
    uploaded_file = st.file_uploader("Escolha um arquivo CSV ou ZIP", type=["csv", "zip"])

    # Bot√£o para carregar dados e inicializar o agente
    if st.button("Carregar Dados e Inicializar Agente") and uploaded_file is not None:
        with st.spinner("Carregando e preparando dados..."):
            load_result = load_and_extract_data(uploaded_file)

        if load_result["status"] == "success":
            st.session_state.df = load_result["df"]

            # 2. Definir a lista final de ferramentas
            tools_with_df = [
                Tool(
                    name=show_descriptive_stats.__name__,
                    description=show_descriptive_stats.__doc__,
                    func=show_descriptive_stats 
                ),
                Tool(
                    name=generate_histogram.__name__,
                    description=generate_histogram.__doc__,
                    func=generate_histogram
                ),
                Tool(
                    name=generate_correlation_heatmap.__name__,
                    description=generate_correlation_heatmap.__doc__,
                    func=generate_correlation_heatmap
                ),
                Tool(
                    name=generate_scatter_plot.__name__,
                    description=generate_scatter_plot.__doc__,
                    func=generate_scatter_plot
                ),
                Tool(
                    name=detect_outliers_isolation_forest.__name__,
                    description=detect_outliers_isolation_forest.__doc__,
                    func=detect_outliers_isolation_forest
                ),
                Tool(
                    name=find_clusters_kmeans.__name__,
                    description=find_clusters_kmeans.__doc__,
                    func=find_clusters_kmeans
                )
            ]

            system_prompt = (
                "Voc√™ √© um agente de An√°lise Explorat√≥ria de Dados (EDA) altamente proficiente, "
                "especializado em datasets de transa√ß√µes financeiras. Seu objetivo √© ajudar o usu√°rio a "
                "entender o dataset, usando as ferramentas dispon√≠veis para gerar estat√≠sticas, gr√°ficos e "
                "modelos de clustering/anomalias. "
                "Sempre que o usu√°rio solicitar uma an√°lise de dados, use a ferramenta apropriada. "
                "Para an√°lises que requerem colunas (como histograma), **voc√™ deve** perguntar ao usu√°rio qual coluna ele deseja, se ele n√£o especificar. "
                "Ao receber o resultado de uma ferramenta (markdown, gr√°fico ou mensagem), sintetize a informa√ß√£o de forma clara e profissional. "
                "Lembre-se: todas as colunas V* e 'Time' e 'Amount' foram convertidas para min√∫sculas ('v*', 'time', 'amount') no DataFrame. "
                "Sua resposta final deve sempre ser em Portugu√™s e oferecer insights."
            )

            st.session_state.agent_executor = initialize_agent(tools_with_df, system_prompt)
            st.success("Dados carregados e agente inicializado! Voc√™ pode come√ßar a perguntar.")

        else:
            st.error(load_result["message"])

    if st.session_state.df is not None:
        st.success(f"DataFrame carregado com {len(st.session_state.df)} linhas e {len(st.session_state.df.columns)} colunas.")
        st.subheader("Visualiza√ß√£o dos Dados (Amostra)")
        st.dataframe(st.session_state.df.head())


# Exibir hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if isinstance(message["content"], pd.DataFrame):
             st.dataframe(message["content"])
        elif isinstance(message["content"], str):
             st.markdown(message["content"])

# Tratamento de entrada do usu√°rio
if prompt_input := st.chat_input("Qual an√°lise voc√™ gostaria de fazer? (Ex: 'Gere um mapa de calor da correla√ß√£o')"):
    
    # 1. Adicionar input do usu√°rio ao chat
    with st.chat_message("user"):
        st.markdown(prompt_input)
    st.session_state.messages.append({"role": "user", "content": prompt_input})
    
    # 2. Executar o agente
    if st.session_state.agent_executor is not None:
        with st.chat_message("assistant"):
            st_callback = st.container()
            
            try:
                full_response = st.session_state.agent_executor.invoke({"input": prompt_input})
                response_content = full_response["output"]

                if isinstance(response_content, dict) and response_content.get("status") in ["success", "error"]:
                    
                    if "message" in response_content:
                        # Exibe e salva a mensagem de texto
                        st_callback.markdown(response_content["message"])
                        st.session_state.messages.append({"role": "assistant", "content": response_content["message"]})
                    
                    if "data" in response_content:
                        # Exibe o DataFrame de estat√≠sticas
                        df_display = pd.read_markdown(response_content["data"])
                        st_callback.dataframe(df_display)
                        # Salva o DataFrame como objeto DataFrame (para exibi√ß√£o futura)
                        st.session_state.messages.append({"role": "assistant", "content": df_display})
                        
                    if "image" in response_content:
                        # Exibe a imagem/gr√°fico no Streamlit
                        st_callback.image(response_content["image"], use_column_width=True)
                        # N√£o salva o objeto BytesIO na mem√≥ria do chat.
                    
                    if response_content.get("status") == "error":
                         st_callback.error(response_content["message"])
                    
                else:
                    # Resposta direta do LLM (sem uso de ferramenta)
                    st_callback.markdown(str(response_content))
                    st.session_state.messages.append({"role": "assistant", "content": str(response_content)})

            except Exception as e:
                error_message = f"Desculpe, ocorreu um erro na an√°lise: {e}"
                st_callback.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
